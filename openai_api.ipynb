{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae4f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "#print('key:', OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2fef8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client =  OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "507c0b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client =  OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input='ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì˜ ë‹¤ìŠ¤ë² ì´ë”ì˜ ì—­í• ì— ëŒ€í•´ í•œì¤„ë¡œ ì„¤ë²™í•´ì¤˜'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "100a5e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ë‹¤ìŠ¤ ë² ì´ë”ëŠ” ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì—ì„œ ì œêµ­ì˜ ë¬´ìë¹„í•œ ì‚¬ë ¹ê´€ì´ì, íƒ€ë½í•œ ì œë‹¤ì´ ì•„ë‚˜í‚¨ ìŠ¤ì¹´ì´ì›Œì»¤ì˜ ìƒˆë¡œìš´ ìì•„ë¡œ, ì€í•˜ê³„ë¥¼ ìœ„í˜‘í•˜ëŠ” ìƒì§•ì ì¸ ì•…ì—­ì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "092ff570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë‹¤ìŠ¤ ë² ì´ë”ëŠ” ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì—ì„œ ê³¼ê±°ì˜ ì˜ì›… ì•„ë‚˜í‚¨ ìŠ¤ì¹´ì´ì›Œì»¤ê°€ íƒ€ë½í•´ ì€í•˜ ì œêµ­ì˜ ìƒì§•ì  ì•…ë‹¹ì´ì, ì•„ë²„ì§€ë¡œì„œ ì£¼ì¸ê³µì˜ ìš´ëª…ì„ ë’¤í”ë“œëŠ” ë¹„ê·¹ì  ì¡´ì¬ì´ë‹¤.\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    instructions='ë‹¹ì‹ ì€ ì˜í™”í‰ë¡ ê°€ì•¼!',\n",
    "    input='ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆì˜ ë‹¤ìŠ¤ë² ì´ë”ì˜ ì—­í• ì— ëŒ€í•´ í•œì¤„ë¡œ ì„¤ëª…í•´ì¤˜'\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¢‹ì€ ì§ˆë¬¸ì´ë„¤ìš”! ì˜¤ëŠ˜ì€ ì–´ë–¤ ìŒì‹ì„ ë¨¹ê³  ì‹¶ì€ì§€ ëª‡ ê°€ì§€ ì§ˆë¬¸ì„ ë“œë ¤ë³¼ê²Œìš”:\n",
      "\n",
      "1. í•œì‹, ì–‘ì‹, ì¤‘ì‹, ì¼ì‹ ë“± íŠ¹ì •í•œ ì¢…ë¥˜ê°€ ë•¡ê¸°ë‚˜ìš”?\n",
      "2. ì§‘ì—ì„œ ë§Œë“¤ì–´ ë“œì‹¤ ê±´ê°€ìš”, ì•„ë‹ˆë©´ ë°°ë‹¬ì´ë‚˜ ì™¸ì‹ ìƒê° ì¤‘ì´ì‹ ê°€ìš”?\n",
      "3. ê°€ë³ê²Œ ë¨¹ê³  ì‹¶ì€ì§€, ë“ ë“ í•œ í•œ ë¼ê°€ í•„ìš”í•œì§€ë„ ê¶ê¸ˆí•´ìš”.\n",
      "4. ì¬ë£Œë‚˜ ìŒì‹ ì•Œë ˆë¥´ê¸°, í”¼í•˜ê³  ì‹¶ì€ ìŒì‹ì´ ìˆìœ¼ì‹ ê°€ìš”?\n",
      "\n",
      "ì˜ˆë¥¼ ë“¤ì–´, ì˜¤ëŠ˜ ê¸°ë¶„ì´ ë§‘ê³  ìƒì¾Œí•˜ë‹¤ë©´ ìƒëŸ¬ë“œë‚˜ ìƒŒë“œìœ„ì¹˜ë¥¼ ì¶”ì²œí•˜ê³ , ë“ ë“ í•œ í•œì‹ì´ ìƒê°ë‚˜ë©´ ê¹€ì¹˜ì°Œê°œë‚˜ ì œìœ¡ë³¶ìŒ, í˜¹ì€ ì°œë‹­ë„ ì¢‹ì•„ìš”. ì…ë§› ë”°ë¼ ë­”ê°€ íŠ¹ë³„íˆ í•´ë³´ê³  ì‹¶ì€ ë©”ë‰´ê°€ ìˆìœ¼ì‹ ì§€ë„ ë§ì”€í•´ì£¼ì‹œë©´ ë§ì¶¤ ë©”ë‰´ ì¶”ì²œë“œë¦´ ìˆ˜ ìˆì–´ìš”! ğŸ˜Š\n",
      "\n",
      "í˜¹ì‹œ ìƒê°ë‚˜ëŠ” ë©”ë‰´, í˜¹ì€ ì˜¤ëŠ˜ì˜ ì»¨ë””ì…˜ ë§ì”€í•´ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”?\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'developer',\n",
    "            'content': 'ìŒì‹ì— ëŒ€í•œ ì´ì•¼ê¸° í•˜ëŠ”ê²ƒì„ ì¢‹ì•„í•´'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'ì˜¤ëŠ˜ì€ ë¬´ì—‡ì„ ë¨¹ì„ê¹Œ?'\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "432da534",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='gpt-4.1',\n",
    "    messages= [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'ìŠ¤íƒ€ì›Œì¦ˆì‹œë¦¬ì¦ˆì— ëŒ€í•´ í•œë¶„ì¥ìœ¼ë¡œ ì„¤ëª…í•´ì¤˜'\n",
    "        }\n",
    "    ]  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d2de517",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ìŠ¤íƒ€ì›Œì¦ˆ ì‹œë¦¬ì¦ˆëŠ” ì„ ê³¼ ì•…ì˜ ëŒ€ë¦½, ì€í•˜ ì œêµ­ê³¼ ë°˜ë€êµ°, ê·¸ë¦¬ê³  í¬ìŠ¤ë¼ëŠ” ì‹ ë¹„í•œ í˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ ë‹¤ì–‘í•œ ì¸ë¬¼ê³¼ ìš°ì£¼ ì„¸ê³„ê´€ì„ ê·¸ë¦° SF ì˜í™” ì‹œë¦¬ì¦ˆì…ë‹ˆë‹¤.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dict(completion.choices[0])\n",
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f60b9ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸: \n",
      "ì•Œê² ì–´ìš”~! ìš°ë¦¬ ì¹œêµ¬ë“¤ ì•ˆë…•í•˜ì„¸ìš”! ğŸ˜Š  \n",
      "ë¬´ì—‡ì´ë“  ê¶ê¸ˆí•œ ê²Œ ìˆìœ¼ë©´ ì„ ìƒë‹˜í•œí…Œ ë¬¼ì–´ë´ë„ ì¢‹ì•„ìš”.  \n",
      "í•¨ê»˜ ì¬ë¯¸ìˆê²Œ ì´ì•¼ê¸°í•´ë³¼ê¹Œìš”?  \n",
      "ë¬´ì—‡ì„ í•˜ê³  ì‹¶ë‚˜ìš”~? ğŸ»ğŸŒˆ\n"
     ]
    }
   ],
   "source": [
    "user_input = input('ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì´ êµ¼ê¸ˆí•˜ì‹ ê°€ìš”? ì§ˆë¬¸ì„ ë‚¨ê²¨ì£¼ì„¸ìš”!!!')\n",
    "print('ì§ˆë¬¸:', user_input)\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=[\n",
    "        {\n",
    "            'role': 'developer',\n",
    "            'content': 'ë„ˆëŠ” ìœ ì¹˜ì› ì„ ìƒë‹˜ì´ì•¼. ì•„ì´ë“¤ì„ ëŒ€í•˜ëŠ”ê²ƒì²˜ëŸ¼ ì´ì•¼ê¸°í•´ì¤˜'\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': user_input\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a60bc3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36193db6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'requests'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_weather\u001b[39m(latitude, longitude):\n\u001b[1;32m      4\u001b[0m     response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.open-meteo.com/v1/forecast?latitude=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlatitude\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&longitude=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlongitude\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'requests'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_weather(latitude, longitude):\n",
    "    response = requests.get(f\"https://api.open-meteo.com/v1/forecast?latitude={latitude}&longitude={longitude}&current=temperature_2m,wind_speed_10m&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m\")\n",
    "    data = response.json()\n",
    "    return data['current']['temperature_2m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77d2e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"name\": \"get_weather\",\n",
    "    \"description\": \"Get current temperature for provided coordinates in celsius.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"latitude\": {\"type\": \"number\"},\n",
    "            \"longitude\": {\"type\": \"number\"}\n",
    "        },\n",
    "    \"required\": [\"latitude\", \"longitude\"],\n",
    "    \"additionalProperties\": False\n",
    "    },\n",
    "    \"strict\": True\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07ed015",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_messages = [{ 'role': 'user', 'content':'ì˜¤ëŠ˜ íŒŒë¦¬ ë‚ ì”¨ ì–´ë•Œ?'}]\n",
    "\n",
    "# í•¨ìˆ˜ í˜¸ì¶œí•˜ëŠ” ê¸°ëŠ¥\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d806cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'arguments': '{\"latitude\":48.8566,\"longitude\":2.3522}',\n",
       " 'call_id': 'call_5akC5g1dyEDCKEpL40sMoiBY',\n",
       " 'name': 'get_weather',\n",
       " 'type': 'function_call',\n",
       " 'id': 'fc_685bae49a6608198832c554beffde293067ceb33fda1e78d',\n",
       " 'status': 'completed'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(response.output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725b06b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "tool_call = response.output[0]\n",
    "args = json.loads(tool_call.arguments)\n",
    "\n",
    "result = get_weather(args[\"latitude\"], args[\"longitude\"])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc89eafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ëŠ˜ íŒŒë¦¬ì˜ í˜„ì¬ ê¸°ì˜¨ì€ ì•½ 23.3Â°Cì…ë‹ˆë‹¤. ë‚ ì”¨ê°€ ê½¤ ì˜¨í™”í•˜ê³  ì¾Œì í•œ í¸ì´ë„¤ìš”! ë” ìì„¸í•œ ì •ë³´(ì˜ˆ: ê°•ìˆ˜ë‚˜ ë°”ëŒ ë“±)ê°€ í•„ìš”í•˜ì‹œë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.\n"
     ]
    }
   ],
   "source": [
    "input_messages.append(tool_call)\n",
    "input_messages.append({\n",
    "    'type' : 'function_call_output',\n",
    "    'call_id': tool_call.call_id,\n",
    "    'output': str(result)\n",
    "})\n",
    "\n",
    "# ìµœì¢… ì‘ë‹µ\n",
    "response2 = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "print(response2.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36efb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.basic_tools import calculate_age, convert_currency, calculate_bmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d295288",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"calculate_age\",\n",
    "        \"description\": \"ì…ë ¥ëœ ìƒë…„ì›”ì¼(YYYY-mm-dd)ë¡œ ë§Œ ë‚˜ì´ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"birthdate\": {\"type\": \"string\", \"description\": \"ìƒë…„ì›”ì¼, í˜•ì‹:YYYY-MM-DD\"}\n",
    "            },\n",
    "        \"required\": [\"birthdate\"],\n",
    "        \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"convert_currency\",\n",
    "        \"description\": \"ì…ë ¥ëœ ë‹¬ëŸ¬(USD)ë¥¼ ì›í™”(KRW)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"amount\": {\"type\": \"number\", \"description\": \"ë‹¬ëŸ¬(USD) ê¸ˆì•¡\"}\n",
    "            },\n",
    "        \"required\": [\"amount\"],\n",
    "        \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"calculate_bmi\",\n",
    "        \"description\": \"í‚¤(cm), ëª¸ë¬´ê²Œ(kg) ì •ë³´ë¥¼ ë°›ì•„ì„œ BMIë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"height\": {\"type\": \"number\", \"description\": \"í‚¤(cm)\"},\n",
    "                \"weight\": {\"type\": \"number\", \"description\": \"ëª¸ë¬´ê²Œ(cm)\"}\n",
    "            },\n",
    "        \"required\": [\"height\", \"weight\"],\n",
    "        \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8e850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ResponseFunctionToolCall(arguments='{\"birthdate\":\"1990-01-01\"}', call_id='call_HpSpiX94iMziDUQRj7RuDGDo', name='calculate_age', type='function_call', id='fc_685caa7beca081998a22d32a26c686a003f75c4e5cee4aab', status='completed'), ResponseFunctionToolCall(arguments='{\"amount\":100}', call_id='call_SI9eZ0fjUQtas872kGzdvvRF', name='convert_currency', type='function_call', id='fc_685caa7c24288199918bc5c74178c9b103f75c4e5cee4aab', status='completed'), ResponseFunctionToolCall(arguments='{\"height\":190,\"weight\":50}', call_id='call_BJKCubcO3Fyfr4jpBlgRiOHa', name='calculate_bmi', type='function_call', id='fc_685caa7c31408199b4edaee8cc35b3bd03f75c4e5cee4aab', status='completed')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_messages = [\n",
    "    {\n",
    "        \"role\" : \"user\",\n",
    "        \"content\": \"ë‚´ ìƒì¼ì€ 1990-01-01 ì´ê³ , 100 ë‹¬ëŸ¬ë¥¼ ê°€ì§€ê³  ìˆëŠ”ë° ì›í™”ë¡œ ë³€í™˜í•´ì¤˜, ê·¸ë¦¬ê³  ë‚´ í‚¤ëŠ” 190cm ì´ê³  ëª¸ë¬´ê²ŒëŠ” 50kg ì´ì•¼ BMI ì ìˆ˜ë¥¼ ì•Œë ¤ì¤˜\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=fn_tools\n",
    ")\n",
    "\n",
    "print(response.output)\n",
    "print(response.output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395f79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResponseFunctionToolCall(arguments='{\"birthdate\":\"1990-01-01\"}', call_id='call_HpSpiX94iMziDUQRj7RuDGDo', name='calculate_age', type='function_call', id='fc_685caa7beca081998a22d32a26c686a003f75c4e5cee4aab', status='completed')\n",
      "ResponseFunctionToolCall(arguments='{\"amount\":100}', call_id='call_SI9eZ0fjUQtas872kGzdvvRF', name='convert_currency', type='function_call', id='fc_685caa7c24288199918bc5c74178c9b103f75c4e5cee4aab', status='completed')\n",
      "ResponseFunctionToolCall(arguments='{\"height\":190,\"weight\":50}', call_id='call_BJKCubcO3Fyfr4jpBlgRiOHa', name='calculate_bmi', type='function_call', id='fc_685caa7c31408199b4edaee8cc35b3bd03f75c4e5cee4aab', status='completed')\n"
     ]
    }
   ],
   "source": [
    "print(response.output[0])\n",
    "print(response.output[1])\n",
    "print(response.output[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80de64f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜¸ì¶œ ë„êµ¬:calculate_age\n",
      "ë§¤ê°œë³€ìˆ˜: {\"birthdate\":\"1990-01-01\"}\n",
      "í˜¸ì¶œ ë„êµ¬:convert_currency\n",
      "ë§¤ê°œë³€ìˆ˜: {\"amount\":100}\n",
      "í˜¸ì¶œ ë„êµ¬:calculate_bmi\n",
      "ë§¤ê°œë³€ìˆ˜: {\"height\":190,\"weight\":50}\n",
      "[{'role': 'user', 'content': 'ë‚´ ìƒì¼ì€ 1990-01-01 ì´ê³ , 100 ë‹¬ëŸ¬ë¥¼ ê°€ì§€ê³  ìˆëŠ”ë° ì›í™”ë¡œ ë³€í™˜í•´ì¤˜, ê·¸ë¦¬ê³  ë‚´ í‚¤ëŠ” 190cm ì´ê³  ëª¸ë¬´ê²ŒëŠ” 50kg ì´ì•¼ BMI ì ìˆ˜ë¥¼ ì•Œë ¤ì¤˜'}, ResponseFunctionToolCall(arguments='{\"birthdate\":\"1990-01-01\"}', call_id='call_HpSpiX94iMziDUQRj7RuDGDo', name='calculate_age', type='function_call', id='fc_685caa7beca081998a22d32a26c686a003f75c4e5cee4aab', status='completed'), {'type': 'function_call_output', 'call_id': 'call_HpSpiX94iMziDUQRj7RuDGDo', 'output': '35'}, ResponseFunctionToolCall(arguments='{\"amount\":100}', call_id='call_SI9eZ0fjUQtas872kGzdvvRF', name='convert_currency', type='function_call', id='fc_685caa7c24288199918bc5c74178c9b103f75c4e5cee4aab', status='completed'), {'type': 'function_call_output', 'call_id': 'call_SI9eZ0fjUQtas872kGzdvvRF', 'output': '133000'}, ResponseFunctionToolCall(arguments='{\"height\":190,\"weight\":50}', call_id='call_BJKCubcO3Fyfr4jpBlgRiOHa', name='calculate_bmi', type='function_call', id='fc_685caa7c31408199b4edaee8cc35b3bd03f75c4e5cee4aab', status='completed'), {'type': 'function_call_output', 'call_id': 'call_BJKCubcO3Fyfr4jpBlgRiOHa', 'output': '13.85'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "if response.output :\n",
    "    for tool_call in response.output:\n",
    "        if tool_call.type == 'function_call':\n",
    "            if tool_call.name == 'calculate_age':\n",
    "                print(f'í˜¸ì¶œ ë„êµ¬:{tool_call.name}')\n",
    "                print(f'ë§¤ê°œë³€ìˆ˜: {tool_call.arguments}')\n",
    "                # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
    "                args = json.loads(tool_call.arguments)\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "                result = calculate_age(args['birthdate'])\n",
    "                input_messages.append(tool_call)\n",
    "                input_messages.append({\n",
    "                    \"type\" : \"function_call_output\",\n",
    "                    \"call_id\": tool_call.call_id,\n",
    "                    \"output\": str(result)\n",
    "                })\n",
    "            \n",
    "            \n",
    "            if tool_call.name == 'convert_currency':\n",
    "                print(f'í˜¸ì¶œ ë„êµ¬:{tool_call.name}')\n",
    "                print(f'ë§¤ê°œë³€ìˆ˜: {tool_call.arguments}')\n",
    "\n",
    "                # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
    "                args = json.loads(tool_call.arguments)\n",
    "\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "                result = convert_currency(args['amount'])\n",
    "\n",
    "                input_messages.append(tool_call)\n",
    "                input_messages.append({\n",
    "                    \"type\" : \"function_call_output\",\n",
    "                    \"call_id\": tool_call.call_id,\n",
    "                    \"output\": str(result)\n",
    "                })\n",
    "            \n",
    "            if tool_call.name == 'calculate_bmi':\n",
    "                print(f'í˜¸ì¶œ ë„êµ¬:{tool_call.name}')\n",
    "                print(f'ë§¤ê°œë³€ìˆ˜: {tool_call.arguments}')\n",
    "\n",
    "                # ë§¤ê°œë³€ìˆ˜ ì¶”ì¶œ\n",
    "                args = json.loads(tool_call.arguments)\n",
    "\n",
    "                # í•¨ìˆ˜ ì‹¤í–‰ ê²°ê³¼\n",
    "                result = calculate_bmi(args['height'],args['weight'])\n",
    "\n",
    "                input_messages.append(tool_call)\n",
    "                input_messages.append({\n",
    "                    \"type\" : \"function_call_output\",\n",
    "                    \"call_id\": tool_call.call_id,\n",
    "                    \"output\": str(result)\n",
    "                })\n",
    "\n",
    "print(input_messages)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1bf33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- ë§Œ ë‚˜ì´ëŠ” 35ì„¸ì…ë‹ˆë‹¤.\n",
      "- 100ë‹¬ëŸ¬ëŠ” í˜„ì¬ í™˜ìœ¨ë¡œ ì•½ 133,000ì›ì…ë‹ˆë‹¤.\n",
      "- í‚¤ 190cm, ëª¸ë¬´ê²Œ 50kgì˜ BMIëŠ” ì•½ 13.85ë¡œ, ì €ì²´ì¤‘ì— í•´ë‹¹í•©ë‹ˆë‹¤. \n",
      "\n",
      "ì¶”ê°€ ì •ë³´ê°€ í•„ìš”í•˜ê±°ë‚˜ ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”!\n"
     ]
    }
   ],
   "source": [
    "response_msg = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input=input_messages,\n",
    "    tools=fn_tools\n",
    ")\n",
    "\n",
    "print(response_msg.output_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b9ac3c",
   "metadata": {},
   "source": [
    "### File Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4829e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from io import BytesIO\n",
    "#from openai import OpenAI\n",
    "\n",
    "#client = OpenAI()\n",
    "\n",
    "def create_file(client, file_path):\n",
    "    if file_path.startswith(\"http://\") or file_path.startswith(\"https://\"):\n",
    "        # Download the file content from the URL\n",
    "        response = requests.get(file_path)\n",
    "        file_content = BytesIO(response.content)\n",
    "        file_name = file_path.split(\"/\")[-1]\n",
    "        file_tuple = (file_name, file_content)\n",
    "        result = client.files.create(\n",
    "            file=file_tuple,\n",
    "            purpose=\"assistants\"\n",
    "        )\n",
    "    else:\n",
    "        # Handle local file path\n",
    "        with open(file_path, \"rb\") as file_content:\n",
    "            result = client.files.create(\n",
    "                file=file_content,\n",
    "                purpose=\"assistants\"\n",
    "            )\n",
    "    print(result.id)\n",
    "    return result.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34382cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file-JVeHeoikzPe3ZdafsP2DLH\n"
     ]
    }
   ],
   "source": [
    "file_id = create_file(client, './howto-sockets.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc15ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_685cb68d844c81918e0fb0ff7a57e2ff\n"
     ]
    }
   ],
   "source": [
    "vector_store = client.vector_stores.create(\n",
    "    name='knowledge_base'\n",
    ")\n",
    "\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807ce23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreFile(id='file-JVeHeoikzPe3ZdafsP2DLH', created_at=1750906661, last_error=None, object='vector_store.file', status='in_progress', usage_bytes=0, vector_store_id='vs_685cb68d844c81918e0fb0ff7a57e2ff', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.vector_stores.files.create(\n",
    "    vector_store_id=vector_store.id,\n",
    "    file_id=file_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4f550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[VectorStoreFile](data=[VectorStoreFile(id='file-JVeHeoikzPe3ZdafsP2DLH', created_at=1750906661, last_error=None, object='vector_store.file', status='completed', usage_bytes=29112, vector_store_id='vs_685cb68d844c81918e0fb0ff7a57e2ff', attributes={}, chunking_strategy=StaticFileChunkingStrategyObject(static=StaticFileChunkingStrategy(chunk_overlap_tokens=400, max_chunk_size_tokens=800), type='static'))], has_more=False, object='list', first_id='file-JVeHeoikzPe3ZdafsP2DLH', last_id='file-JVeHeoikzPe3ZdafsP2DLH')\n"
     ]
    }
   ],
   "source": [
    "result_list = client.vector_stores.files.list(\n",
    "    vector_store_id=vector_store.id\n",
    ")\n",
    "\n",
    "print(result_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161bf4db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(id='resp_685cd0d3fcdc8199ac3bbff06b88803f05f92a27e588b3bc', created_at=1750913236.0, error=None, incomplete_details=None, instructions=None, metadata={}, model='gpt-4.1-2025-04-14', object='response', output=[ResponseFileSearchToolCall(id='fs_685cd0d465fc8199a5ff176733a0aade05f92a27e588b3bc', queries=['íŒŒì´ì¬ ì½”ë“œë¡œ ì†Œì¼“ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤˜', 'íŒŒì´ì¬ ì†Œì¼“ ì˜ˆì‹œ', 'íŒŒì´ì¬ ì†Œì¼“ ìƒì„±', 'íŒŒì´ì¬ socket ì‚¬ìš©ë²•', 'íŒŒì´ì¬ ì„œë²„ í´ë¼ì´ì–¸íŠ¸ ì˜ˆì œ'], status='completed', type='file_search_call', results=None), ResponseOutputMessage(id='msg_685cd0d6e42c8199aa955f44b338768f05f92a27e588b3bc', content=[ResponseOutputText(annotations=[AnnotationFileCitation(file_id='file-JVeHeoikzPe3ZdafsP2DLH', filename='howto-sockets.pdf', index=1087, type='file_citation')], text='íŒŒì´ì¬ì—ì„œ ì†Œì¼“ì„ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì •ë¦¬í•˜ë©´ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\\n\\n### 1. í´ë¼ì´ì–¸íŠ¸ ì†Œì¼“ ë§Œë“¤ê¸°\\n\\n```python\\nimport socket\\n\\n# 1. ì†Œì¼“ ê°ì²´ ìƒì„± (AF_INET = IPv4, SOCK_STREAM = TCP)\\ns = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n# 2. ì„œë²„ì— ì—°ê²° (í˜¸ìŠ¤íŠ¸, í¬íŠ¸)\\ns.connect((\\'www.example.com\\', 80))\\n# 3. ë°ì´í„° ì†¡ì‹ /ìˆ˜ì‹  (ex: HTTP GET ìš”ì²­ ë³´ë‚´ê¸°)\\ns.sendall(b\"GET / HTTP/1.1\\\\r\\\\nHost: www.example.com\\\\r\\\\n\\\\r\\\\n\")\\nresponse = s.recv(4096)\\nprint(response)\\n# 4. ì†Œì¼“ ë‹«ê¸°\\ns.close()\\n```\\n\\n### 2. ì„œë²„ ì†Œì¼“ ë§Œë“¤ê¸°\\n\\n```python\\nimport socket\\n\\n# 1. ì†Œì¼“ ê°ì²´ ìƒì„±\\nserversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n# 2. ì£¼ì†Œì™€ í¬íŠ¸ í• ë‹¹(bind)\\nserversocket.bind((\\'localhost\\', 12345))  # ì¼ë°˜ì ìœ¼ë¡œ ì—°ìŠµì´ë‚˜ í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 4ìë¦¬ ì´ìƒì˜ í¬íŠ¸ ì‚¬ìš©\\n# 3. ì—°ê²° ìš”ì²­ ëŒ€ê¸° ìƒíƒœë¡œ ì „í™˜\\nserversocket.listen(5)  # ë™ì‹œì— ìµœëŒ€ 5ê°œê¹Œì§€ ëŒ€ê¸° ê°€ëŠ¥\\nprint(\\'ì„œë²„ê°€ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.\\')\\n\\nwhile True:\\n    # 4. í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ìˆ˜ë½\\n    clientsocket, address = serversocket.accept()\\n    print(\\'ì—°ê²°ë¨:\\', address)\\n    # 5. ë°ì´í„° ì†¡ìˆ˜ì‹ \\n    clientsocket.sendall(b\"Hello, client!\")\\n    clientsocket.close()\\n```\\n\\n#### ìš”ì•½\\n- `socket.socket()`ìœ¼ë¡œ ì†Œì¼“ì„ ë§Œë“¤ê³ , \\n- í´ë¼ì´ì–¸íŠ¸ëŠ” `connect()`, ì„œë²„ëŠ” `bind()+listen()+accept()`ë¡œ ë™ì‘í•©ë‹ˆë‹¤. \\n- ë°ì´í„° ì†¡ìˆ˜ì‹ ì€ `send()`, `recv()`ë¡œ í•©ë‹ˆë‹¤. \\n- ë§ˆì§€ë§‰ì—ëŠ” ê¼­ `close()`ë¡œ ì†Œì¼“ì„ ë‹«ì•„ì£¼ì„¸ìš”.\\n\\nê¶ê¸ˆí•œ ì ì´ ìˆìœ¼ë©´ ë” ìì„¸í•œ ì˜ˆì‹œë„ ì„¤ëª…í•´ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤!', type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], parallel_tool_calls=True, temperature=1.0, tool_choice='required', tools=[FileSearchTool(type='file_search', vector_store_ids=['vs_685cb68d844c81918e0fb0ff7a57e2ff'], filters=None, max_num_results=20, ranking_options=RankingOptions(ranker='auto', score_threshold=0.0))], top_p=1.0, background=False, max_output_tokens=None, previous_response_id=None, prompt=None, reasoning=Reasoning(effort=None, generate_summary=None, summary=None), service_tier='default', status='completed', text=ResponseTextConfig(format=ResponseFormatText(type='text')), truncation='disabled', usage=ResponseUsage(input_tokens=11872, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=526, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=12398), user=None, max_tool_calls=None, store=True)\n"
     ]
    }
   ],
   "source": [
    "response = client.responses.create(\n",
    "    model='gpt-4.1',\n",
    "    input='íŒŒì´ì¬ ì½”ë“œë¡œ ì†Œì¼“ ë§Œë“œëŠ” ë°©ë²•ì„ ê°„ë‹¨í•˜ê²Œ ì„¤ëª…í•´ì¤˜',\n",
    "    tools=[{\n",
    "        \"type\" : \"file_search\",\n",
    "        \"vector_store_ids\" : [vector_store.id]\n",
    "    }],\n",
    "    tool_choice='required'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502e242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'resp_685cd034f590819ab88a10e0baebd37300b65382008f721d', 'created_at': 1750913076.0, 'error': None, 'incomplete_details': None, 'instructions': None, 'metadata': {}, 'model': 'gpt-4.1-2025-04-14', 'object': 'response', 'output': [ResponseOutputMessage(id='msg_685cd0356944819a82e31b131382838900b65382008f721d', content=[ResponseOutputText(annotations=[], text=\"íŒŒì´ì¬ì—ì„œ ì†Œì¼“ì„ ë§Œë“œëŠ” ë°©ë²•ì€ ë¹„êµì  ê°„ë‹¨í•©ë‹ˆë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ socket ëª¨ë“ˆì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì•„ë˜ëŠ” ê°„ë‹¨í•œ ê³¼ì •ê³¼ ì˜ˆì‹œì…ë‹ˆë‹¤.\\n\\n### ê¸°ë³¸ ìˆœì„œ\\n\\n1. socket ëª¨ë“ˆ ì„í¬íŠ¸\\n2. ì†Œì¼“ ê°ì²´ ìƒì„± (`socket.socket()`)\\n3. (ì„œë²„ì˜ ê²½ìš°) ì†Œì¼“ì— ì£¼ì†Œì™€ í¬íŠ¸ í• ë‹¹ (`bind()`)\\n4. (ì„œë²„ì˜ ê²½ìš°) í´ë¼ì´ì–¸íŠ¸ì˜ ì—°ê²° ìš”ì²­ ëŒ€ê¸° (`listen()`)\\n5. (ì„œë²„ì˜ ê²½ìš°) í´ë¼ì´ì–¸íŠ¸ì˜ ì—°ê²° ìˆ˜ë½ (`accept()`)\\n6. ë°ì´í„° ì†¡ìˆ˜ì‹  (`send()`, `recv()`)\\n7. ì†Œì¼“ ë‹«ê¸° (`close()`)\\n\\n### TCP ì„œë²„ ì˜ˆì œ\\n```python\\nimport socket\\n\\n# 1. ì†Œì¼“ ê°ì²´ ìƒì„± (AF_INET: IPv4, SOCK_STREAM: TCP)\\nserver_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\n\\n# 2. ì£¼ì†Œì™€ í¬íŠ¸ í• ë‹¹\\nserver_socket.bind(('localhost', 12345))\\n\\n# 3. ì—°ê²° ìš”ì²­ ëŒ€ê¸°\\nserver_socket.listen(1)\\nprint('ì„œë²„ ëŒ€ê¸° ì¤‘...')\\n\\n# 4. ì—°ê²° ìˆ˜ë½\\nclient_socket, addr = server_socket.accept()\\nprint('ì—°ê²°ë¨:', addr)\\n\\n# 5. ë°ì´í„° ìˆ˜ì‹  ë° ì†¡ì‹ \\ndata = client_socket.recv(1024)\\nprint('ë°›ì€ ë°ì´í„°:', data.decode())\\nclient_socket.sendall('Hello, Client!'.encode())\\n\\n# 6. ì†Œì¼“ ë‹«ê¸°\\nclient_socket.close()\\nserver_socket.close()\\n```\\n\\n### TCP í´ë¼ì´ì–¸íŠ¸ ì˜ˆì œ\\n```python\\nimport socket\\n\\nclient_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\\nclient_socket.connect(('localhost', 12345))\\n\\nclient_socket.sendall('Hello, Server!'.encode())\\ndata = client_socket.recv(1024)\\nprint('ë°›ì€ ë°ì´í„°:', data.decode())\\n\\nclient_socket.close()\\n```\\n\\n#### ì£¼ìš” í¬ì¸íŠ¸\\n- ì„œë²„ì™€ í´ë¼ì´ì–¸íŠ¸ ëª¨ë‘ `socket.socket()`ìœ¼ë¡œ ì†Œì¼“ ê°ì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤.\\n- ì„œë²„ëŠ” `bind()`, `listen()`, `accept()` ìˆœìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\\n- í´ë¼ì´ì–¸íŠ¸ëŠ” `connect()`ë¡œ ì„œë²„ì— ì—°ê²°í•©ë‹ˆë‹¤.\\n- ë°ì´í„° ì†¡ìˆ˜ì‹ ì€ `sendall()`ê³¼ `recv()`ë¡œ ì£¼ê³ ë°›ìŠµë‹ˆë‹¤.\\n\\në” ê¶ê¸ˆí•œ ì  ìˆìœ¼ë©´ ì§ˆë¬¸í•´ ì£¼ì„¸ìš”!\", type='output_text', logprobs=None)], role='assistant', status='completed', type='message')], 'parallel_tool_calls': True, 'temperature': 1.0, 'tool_choice': 'auto', 'tools': [FileSearchTool(type='file_search', vector_store_ids=['vs_685cb68d844c81918e0fb0ff7a57e2ff'], filters=None, max_num_results=20, ranking_options=RankingOptions(ranker='auto', score_threshold=0.0))], 'top_p': 1.0, 'background': False, 'max_output_tokens': None, 'previous_response_id': None, 'prompt': None, 'reasoning': Reasoning(effort=None, generate_summary=None, summary=None), 'service_tier': 'default', 'status': 'completed', 'text': ResponseTextConfig(format=ResponseFormatText(type='text')), 'truncation': 'disabled', 'usage': ResponseUsage(input_tokens=812, input_tokens_details=InputTokensDetails(cached_tokens=0), output_tokens=497, output_tokens_details=OutputTokensDetails(reasoning_tokens=0), total_tokens=1309), 'user': None, 'max_tool_calls': None, 'store': True}\n"
     ]
    }
   ],
   "source": [
    "print(dict(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a130a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Using cached streamlit-1.46.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting altair<6,>=4.0 (from streamlit)\n",
      "  Using cached altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=4.0 (from streamlit)\n",
      "  Using cached cachetools-6.1.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting numpy<3,>=1.23 (from streamlit)\n",
      "  Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: packaging<26,>=20 in ./.venv/lib/python3.9/site-packages (from streamlit) (25.0)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
      "  Using cached pandas-2.3.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (91 kB)\n",
      "Collecting pillow<12,>=7.1.0 (from streamlit)\n",
      "  Using cached pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (8.9 kB)\n",
      "Collecting protobuf<7,>=3.20 (from streamlit)\n",
      "  Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Using cached pyarrow-20.0.0-cp39-cp39-macosx_12_0_arm64.whl.metadata (3.3 kB)\n",
      "Collecting requests<3,>=2.27 (from streamlit)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in ./.venv/lib/python3.9/site-packages (from streamlit) (4.14.0)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in ./.venv/lib/python3.9/site-packages (from streamlit) (6.5.1)\n",
      "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
      "  Using cached narwhals-1.44.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3,>=2.27->streamlit)\n",
      "  Using cached charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair<6,>=4.0->streamlit)\n",
      "  Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
      "  Using cached rpds_py-0.25.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Using cached streamlit-1.46.0-py3-none-any.whl (10.1 MB)\n",
      "Using cached altair-5.5.0-py3-none-any.whl (731 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-6.1.0-py3-none-any.whl (11 kB)\n",
      "Using cached click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Using cached GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached numpy-2.0.2-cp39-cp39-macosx_14_0_arm64.whl (5.3 MB)\n",
      "Using cached pandas-2.3.0-cp39-cp39-macosx_11_0_arm64.whl (10.8 MB)\n",
      "Using cached pillow-11.2.1-cp39-cp39-macosx_11_0_arm64.whl (3.0 MB)\n",
      "Downloading protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp39-cp39-macosx_10_9_universal2.whl (201 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp39-cp39-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached narwhals-1.44.0-py3-none-any.whl (365 kB)\n",
      "Using cached pyarrow-20.0.0-cp39-cp39-macosx_12_0_arm64.whl (30.8 MB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.25.1-cp39-cp39-macosx_11_0_arm64.whl (359 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, urllib3, tzdata, toml, tenacity, smmap, rpds-py, pyarrow, protobuf, pillow, numpy, narwhals, MarkupSafe, click, charset_normalizer, cachetools, blinker, attrs, requests, referencing, pandas, jinja2, gitdb, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m29/29\u001b[0m [streamlit]29\u001b[0m [streamlit]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 altair-5.5.0 attrs-25.3.0 blinker-1.9.0 cachetools-6.1.0 charset_normalizer-3.4.2 click-8.1.8 gitdb-4.0.12 gitpython-3.1.44 jinja2-3.1.6 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 narwhals-1.44.0 numpy-2.0.2 pandas-2.3.0 pillow-11.2.1 protobuf-6.31.1 pyarrow-20.0.0 pydeck-0.9.1 pytz-2025.2 referencing-0.36.2 requests-2.32.4 rpds-py-0.25.1 smmap-5.0.2 streamlit-1.46.0 tenacity-9.1.2 toml-0.10.2 tzdata-2025.2 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7177628",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac0b75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54a51a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
